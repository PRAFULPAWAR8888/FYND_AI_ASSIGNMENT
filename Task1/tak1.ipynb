{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38cdf072",
   "metadata": {},
   "source": [
    "#  **Fynd-Ai-Intern-Assessment Date 5/12/2025**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0233562c",
   "metadata": {},
   "source": [
    "#### **Importing Required Librareis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "94f89307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import json\n",
    "import ollama\n",
    "from ollama import Client\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "import ast\n",
    "import re\n",
    "from typing import Any, Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6e4c9d",
   "metadata": {},
   "source": [
    "#### **Some Data Operations on Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6f2dbd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "data = pd.read_csv(\"yelp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7ad4008f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9yKzy9PApeiPPOUJEtnvkg</td>\n",
       "      <td>2011-01-26</td>\n",
       "      <td>fWKvX83p0-ka4JS3dc6E5A</td>\n",
       "      <td>5</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>review</td>\n",
       "      <td>rLtl8ZkDX5vH5nAx9C3q5Q</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZRJwVLyzEJq1VAihDhYiow</td>\n",
       "      <td>2011-07-27</td>\n",
       "      <td>IjZ33sJrzXqU-0X6U8NwyA</td>\n",
       "      <td>5</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>review</td>\n",
       "      <td>0a2KyEL0d3Yb1V6aivbIuQ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6oRAC4uyJCsJl1X0WZpVSA</td>\n",
       "      <td>2012-06-14</td>\n",
       "      <td>IESLBzqUCLdSzSqm0eCSxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "      <td>review</td>\n",
       "      <td>0hT2KtfLiobPvh6cDC8JQg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_1QQZuf4zZOyFCvXc0o6Vg</td>\n",
       "      <td>2010-05-27</td>\n",
       "      <td>G-WvGaISbqqaMHlNnByodA</td>\n",
       "      <td>5</td>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>uZetl9T0NcROGOyFfughhg</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6ozycU1RpktNG2-1BroVtw</td>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>1uJFq2r5QfJG_6ExMRCaGw</td>\n",
       "      <td>5</td>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>vYmM4KTsC8ZfQBg-j5MWkw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id        date               review_id  stars  \\\n",
       "0  9yKzy9PApeiPPOUJEtnvkg  2011-01-26  fWKvX83p0-ka4JS3dc6E5A      5   \n",
       "1  ZRJwVLyzEJq1VAihDhYiow  2011-07-27  IjZ33sJrzXqU-0X6U8NwyA      5   \n",
       "2  6oRAC4uyJCsJl1X0WZpVSA  2012-06-14  IESLBzqUCLdSzSqm0eCSxQ      4   \n",
       "3  _1QQZuf4zZOyFCvXc0o6Vg  2010-05-27  G-WvGaISbqqaMHlNnByodA      5   \n",
       "4  6ozycU1RpktNG2-1BroVtw  2012-01-05  1uJFq2r5QfJG_6ExMRCaGw      5   \n",
       "\n",
       "                                                text    type  \\\n",
       "0  My wife took me here on my birthday for breakf...  review   \n",
       "1  I have no idea why some people give bad review...  review   \n",
       "2  love the gyro plate. Rice is so good and I als...  review   \n",
       "3  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...  review   \n",
       "4  General Manager Scott Petello is a good egg!!!...  review   \n",
       "\n",
       "                  user_id  cool  useful  funny  \n",
       "0  rLtl8ZkDX5vH5nAx9C3q5Q     2       5      0  \n",
       "1  0a2KyEL0d3Yb1V6aivbIuQ     0       0      0  \n",
       "2  0hT2KtfLiobPvh6cDC8JQg     0       1      0  \n",
       "3  uZetl9T0NcROGOyFfughhg     1       2      0  \n",
       "4  vYmM4KTsC8ZfQBg-j5MWkw     0       0      0  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "26f7d185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   business_id  10000 non-null  object\n",
      " 1   date         10000 non-null  object\n",
      " 2   review_id    10000 non-null  object\n",
      " 3   stars        10000 non-null  int64 \n",
      " 4   text         10000 non-null  object\n",
      " 5   type         10000 non-null  object\n",
      " 6   user_id      10000 non-null  object\n",
      " 7   cool         10000 non-null  int64 \n",
      " 8   useful       10000 non-null  int64 \n",
      " 9   funny        10000 non-null  int64 \n",
      "dtypes: int64(4), object(6)\n",
      "memory usage: 781.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info() # check for null values and data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f55b6c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape # check number of rows and columns\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e1cfe7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract needed columns\n",
    "data = data[['text','stars']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "464b743c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shap of the new dataframe\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6501b9fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  stars\n",
       "0  My wife took me here on my birthday for breakf...      5\n",
       "1  I have no idea why some people give bad review...      5\n",
       "2  love the gyro plate. Rice is so good and I als...      4\n",
       "3  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...      5\n",
       "4  General Manager Scott Petello is a good egg!!!...      5"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8cf06f1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>First visit...Had lunch here today - used my G...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>Should be called house of deliciousness!\\n\\nI ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>I recently visited Olive and Ivy for business ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>My nephew just moved to Scottsdale recently so...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>4-5 locations.. all 4.5 star average.. I think...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  stars\n",
       "9995  First visit...Had lunch here today - used my G...      3\n",
       "9996  Should be called house of deliciousness!\\n\\nI ...      4\n",
       "9997  I recently visited Olive and Ivy for business ...      4\n",
       "9998  My nephew just moved to Scottsdale recently so...      2\n",
       "9999  4-5 locations.. all 4.5 star average.. I think...      5"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail() # check last few rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "190a60f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop null values if any\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "dd887a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the final shape of the dataset\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "35b9d316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove very long reviews (more than 500 words)\n",
    "data  = data[data['text'].str.split().apply(len)<=500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "05148b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9847, 2)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6430ac61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampel 200 rows for faster processing\n",
    "data = data.sample(10, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "587bb9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the text data\n",
    "data['text'] = (\n",
    "    data['text']\n",
    "    .str.replace('\\n', ' ')\n",
    "    .str.replace('\"', \"'\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "57498294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  stars\n",
      "0  This place has a great selection of Korean dis...      4\n",
      "1  This place is the best place I've found so far...      5\n",
      "2  Okay, I will start out by saying that I just p...      5\n",
      "3  My husband and I heard great reviews about thi...      1\n",
      "4  Where I live in Tempe, I can walk to the end o...      3\n",
      "5  The place did not disappoint. The moment we st...      5\n",
      "6  I've been going here for the past 9+ years and...      3\n",
      "7  I love their turkey and provolone cold sub! De...      5\n",
      "8  Such a great oriental market!  Unusual fresh p...      4\n",
      "9  At length: A trip to Kauai for our friends' we...      5\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ef823f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index after dropping rows\n",
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "322a963a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert text column name to review for better understanding\n",
    "data = data.rename(columns={'text': 'review'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ed7173bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['review', 'stars'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# print the column names\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "cfd7cc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "review = data['review'].iloc[0] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aea752d",
   "metadata": {},
   "source": [
    "# **I am using a dataset size of (10, 2) because the free-tier API key cannot handle processing all 200 records. I also tried running it locally using Ollama, but my system is slow, so I chose to work with only 10 samples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "76749294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final shape of the dataset: (10, 2)\n",
      "The columns in the dataset are: ['review', 'stars']\n"
     ]
    }
   ],
   "source": [
    "print(\"Final shape of the dataset:\", data.shape)\n",
    "print(\"The columns in the dataset are:\", data.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f79d09",
   "metadata": {},
   "source": [
    "#### **LLM Operations On Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "babcbdf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "90fed8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get API key from environment variable\n",
    "api  = os.getenv(\"GAK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "57fcfdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set it in Openai client\n",
    "client = OpenAI(\n",
    "    api_key=api,\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4425116e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "prompt_1 = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"\"\"\n",
    "You classify Yelp reviews into 1-5 stars.\n",
    "Your output must be valid JSON and must not contain extra text.\n",
    "Star definitions:\n",
    "1 = very negative\n",
    "2 = negative\n",
    "3 = neutral/mixed\n",
    "4 = positive\n",
    "5 = very positive\n",
    "\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"\"\"\n",
    "Review: \"{review}\"\n",
    "\n",
    "Return ONLY the JSON object:\n",
    "{{\n",
    "  \"predicted_stars\": <integer>,\n",
    "  \"explanation\": \"short reason\"\n",
    "}}\n",
    "\"\"\"\n",
    "    }\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3614f7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"predicted_stars\": 5, \"explanation\": \"The reviewer uses positive language and mentions specific menu items, as well as a family favorite, suggesting a very positive experience.\"}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "response = ollama.chat(\n",
    "    model=\"llama3.2:latest\",\n",
    "    messages=prompt_1\n",
    ")\n",
    "\n",
    "# Extract only the text from the model\n",
    "message_text = response[\"message\"][\"content\"]\n",
    "\n",
    "print(message_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a684374b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_2 = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"\"\"\n",
    "You classify Yelp reviews into 1-5 stars.\n",
    "Your output must be valid JSON and contain no additional text.\n",
    "Follow the format shown in the examples.\n",
    "\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Review: 'Terrible food, rude staff.'\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": '{\"predicted_stars\": 1, \"explanation\": \"very negative experience\"}'\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Review: 'Great service and delicious food!'\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": '{\"predicted_stars\": 5, \"explanation\": \"very positive\"}'\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f'Review: \"{review}\"'\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "faaebfdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"predicted_stars\": 5, \"explanation\": \"\"}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response = ollama.chat(\n",
    "    model=\"llama3.2:latest\",\n",
    "    messages=prompt_2\n",
    ")\n",
    "\n",
    "# Extract only the text from the model\n",
    "message_text = response[\"message\"][\"content\"]\n",
    "\n",
    "print(message_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a9b207b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_3 = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"\"\"\n",
    "Think step-by-step internally but DO NOT reveal your reasoning.\n",
    "Only return the final JSON output.\n",
    "Ensure the JSON is valid and contains no extra text.\n",
    "\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"\"\"\n",
    "Review: \"{review}\"\n",
    "\n",
    "Return JSON in the following format:\n",
    "{{\n",
    "  \"predicted_stars\": <integer>,\n",
    "  \"explanation\": \"brief reason\"\n",
    "}}\n",
    "\"\"\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7ed56df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"predicted_stars\": 4,\n",
      "  \"explanation\": \"Overall positive review with minor complaints about service speed\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response = ollama.chat(\n",
    "    model=\"llama3.2:latest\",\n",
    "    messages=prompt_3\n",
    ")\n",
    "\n",
    "# Extract only the text from the model\n",
    "message_text = response[\"message\"][\"content\"]\n",
    "\n",
    "print(message_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f20e968a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- CONFIG ----------\n",
    "MODEL_NAME = \"llama3.2:latest\"   # change to phi3 or another model if you prefer\n",
    "OLLAMA_HOST = \"http://localhost:11434\"\n",
    "REQUEST_DELAY = 0.2              # seconds between requests (tweak if memory thrashes)\n",
    "MAX_RETRIES = 3\n",
    "# ---------------------------\n",
    "\n",
    "# Connect to local Ollama (reuse your client if already created)\n",
    "try:\n",
    "    client = Client(host=OLLAMA_HOST)\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Failed to create Ollama client: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "83c2d70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Helpers ----------\n",
    "def safe_json_parse(text: str) -> Optional[Any]:\n",
    "    \"\"\"Try to parse model output into a Python object.\n",
    "       Returns parsed object (dict/list) or None.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return None\n",
    "    txt = text.strip()\n",
    "\n",
    "    # remove code fences if present\n",
    "    txt = re.sub(r\"^```(?:json)?\\s*\", \"\", txt)\n",
    "    txt = re.sub(r\"\\s*```$\", \"\", txt)\n",
    "\n",
    "    # 1) strict JSON\n",
    "    try:\n",
    "        return json.loads(txt)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # 2) python literal (single quotes allowed)\n",
    "    try:\n",
    "        return ast.literal_eval(txt)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # 3) extract first {...} or [...] block and try again\n",
    "    m = re.search(r\"(\\{[\\s\\S]*?\\}|\\[[\\s\\S]*?\\])\", txt)\n",
    "    if m:\n",
    "        candidate = m.group(0)\n",
    "        try:\n",
    "            return json.loads(candidate)\n",
    "        except Exception:\n",
    "            pass\n",
    "        try:\n",
    "            return ast.literal_eval(candidate)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4c31f019",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract star number helpers\n",
    "def extract_star_number_from_parsed(parsed: Any) -> Optional[int]:\n",
    "    \"\"\"Given a parsed object (dict/list), try to extract an integer star 1..5.\"\"\"\n",
    "    if isinstance(parsed, dict):\n",
    "        for key in (\"predicted_stars\", \"predicted_rating\", \"rating\", \"stars\"):\n",
    "            if key in parsed:\n",
    "                try:\n",
    "                    val = int(parsed[key])\n",
    "                    if 1 <= val <= 5:\n",
    "                        return val\n",
    "                except:\n",
    "                    pass\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0c3069af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_star_number_from_text(text: str) -> Optional[int]:\n",
    "    \"\"\"Try to extract integer star 1..5 from text using regex fallback.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return None\n",
    "    # find standalone digit between 1 and 5 (prefer full word boundaries)\n",
    "    m = re.search(r\"\\b([1-5])\\b\", text)\n",
    "    if m:\n",
    "        try:\n",
    "            return int(m.group(1))\n",
    "        except:\n",
    "            pass\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f9d4a4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_star_number(text: str) -> Optional[int]:\n",
    "    \"\"\"Combine methods: attempt parse then regex fallback.\"\"\"\n",
    "    parsed = safe_json_parse(text)\n",
    "    s = extract_star_number_from_parsed(parsed)\n",
    "    if s is not None:\n",
    "        return s\n",
    "    # fallback to regex on raw text\n",
    "    return extract_star_number_from_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "18b98460",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_1lm(messages, max_retries=MAX_RETRIES, init_backoff=1.0):\n",
    "    \"\"\"Call Ollama with retries. Returns raw string response (or '{}' if failure).\"\"\"\n",
    "    backoff = init_backoff\n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        try:\n",
    "            resp = client.chat(model=MODEL_NAME, messages=messages, options={\"temperature\": 0})\n",
    "            # expected shape: {'message': {'content': '...'}, ...}\n",
    "            if isinstance(resp, dict):\n",
    "                if \"message\" in resp and isinstance(resp[\"message\"], dict) and \"content\" in resp[\"message\"]:\n",
    "                    return resp[\"message\"][\"content\"]\n",
    "                if \"choices\" in resp and len(resp[\"choices\"]) > 0:\n",
    "                    c = resp[\"choices\"][0]\n",
    "                    if isinstance(c, dict) and \"message\" in c and \"content\" in c[\"message\"]:\n",
    "                        return c[\"message\"][\"content\"]\n",
    "            # fallback: stringify\n",
    "            return str(resp)\n",
    "        except Exception as e:\n",
    "            err = str(e)\n",
    "            print(f\"[run_1lm] attempt {attempt}/{max_retries} error: {err}\")\n",
    "            # Do not aggressively retry on memory / model-not-found errors\n",
    "            if \"memory\" in err.lower() or \"not found\" in err.lower():\n",
    "                return \"{}\"\n",
    "            if attempt < max_retries:\n",
    "                time.sleep(backoff)\n",
    "                backoff *= 2\n",
    "            else:\n",
    "                return \"{}\"\n",
    "    return \"{}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6a76cbc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting processing 10 reviews with model llama3.2:latest ...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ---------- Main processing ----------\n",
    "# Ensure data exists\n",
    "try:\n",
    "    _ = data\n",
    "except NameError:\n",
    "    raise RuntimeError(\"DataFrame `data` not found. Load your CSV into `data` before running this cell.\")\n",
    "\n",
    "results = []\n",
    "n = len(data)\n",
    "print(f\"Starting processing {n} reviews with model {MODEL_NAME} ...\")\n",
    "\n",
    "# Counters for per-prompt JSON validity\n",
    "p1_json_count = 0\n",
    "p2_json_count = 0\n",
    "p3_json_count = 0\n",
    "\n",
    "# Counters for per-prompt correct predictions\n",
    "p1_correct = 0\n",
    "p2_correct = 0\n",
    "p3_correct = 0\n",
    "\n",
    "# For per-prompt predicted star arrays (for optional confusion matrix)\n",
    "p1_preds = []\n",
    "p2_preds = []\n",
    "p3_preds = []\n",
    "actuals = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "643cebac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10/10 reviews. Latest predicted: 2\n"
     ]
    }
   ],
   "source": [
    "# Iterate over each review\n",
    "for idx, row in data.iterrows():\n",
    "    review_text = str(row.get(\"review\", \"\")).strip()\n",
    "    actual = row.get(\"stars\", None)\n",
    "    actuals.append(actual)\n",
    "\n",
    "    # Prompt 1 (zero-shot)\n",
    "    msgs_1 = [\n",
    "        {\"role\": \"system\", \"content\": \"You classify Yelp reviews into 1-5 stars. Return VALID JSON ONLY. Do not include any text outside the JSON object. Use keys: predicted_stars (integer 1-5), explanation (short string).\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Review: \\\"{review_text}\\\"\\n\\nReturn JSON with keys predicted_stars (int 1-5) and explanation (string).\"}\n",
    "    ]\n",
    "    raw_1 = run_1lm(msgs_1)\n",
    "    parsed_1 = safe_json_parse(raw_1)\n",
    "    star_1 = extract_star_number_from_parsed(parsed_1) if parsed_1 is not None else extract_star_number(raw_1)\n",
    "    if parsed_1 is not None:\n",
    "        p1_json_count += 1\n",
    "    p1_preds.append(star_1)\n",
    "    if star_1 is not None and actual is not None and star_1 == int(actual):\n",
    "        p1_correct += 1\n",
    "\n",
    "    # Prompt 2 (few-shot)\n",
    "    msgs_2 = [\n",
    "        {\"role\": \"system\", \"content\": \"You classify Yelp reviews into 1-5 stars. Return VALID JSON ONLY. Do not include any text outside the JSON object.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Review: 'Terrible food, rude staff.'\"},\n",
    "        {\"role\": \"assistant\", \"content\": '{\"predicted_stars\": 1, \"explanation\": \"very negative\"}'},\n",
    "        {\"role\": \"user\", \"content\": \"Review: 'Great service and delicious food!'\"},\n",
    "        {\"role\": \"assistant\", \"content\": '{\"predicted_stars\": 5, \"explanation\": \"very positive\"}'},\n",
    "        {\"role\": \"user\", \"content\": f\"Review: \\\"{review_text}\\\"\\n\\nReturn JSON with keys predicted_stars (int 1-5) and explanation (string).\"}\n",
    "    ]\n",
    "    raw_2 = run_1lm(msgs_2)\n",
    "    parsed_2 = safe_json_parse(raw_2)\n",
    "    star_2 = extract_star_number_from_parsed(parsed_2) if parsed_2 is not None else extract_star_number(raw_2)\n",
    "    if parsed_2 is not None:\n",
    "        p2_json_count += 1\n",
    "    p2_preds.append(star_2)\n",
    "    if star_2 is not None and actual is not None and star_2 == int(actual):\n",
    "        p2_correct += 1\n",
    "\n",
    "    # Prompt 3 (chain-of-thought instruction but ask to return only final JSON)\n",
    "    msgs_3 = [\n",
    "        {\"role\": \"system\", \"content\": \"Think step-by-step internally, but DO NOT reveal your chain-of-thought. Return VALID JSON ONLY with keys predicted_stars (int 1-5) and explanation (string).\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Review: \\\"{review_text}\\\"\\n\\nReturn JSON with keys predicted_stars (int 1-5) and explanation (string).\"}\n",
    "    ]\n",
    "    raw_3 = run_1lm(msgs_3)\n",
    "    parsed_3 = safe_json_parse(raw_3)\n",
    "    star_3 = extract_star_number_from_parsed(parsed_3) if parsed_3 is not None else extract_star_number(raw_3)\n",
    "    if parsed_3 is not None:\n",
    "        p3_json_count += 1\n",
    "    p3_preds.append(star_3)\n",
    "    if star_3 is not None and actual is not None and star_3 == int(actual):\n",
    "        p3_correct += 1\n",
    "\n",
    "    # Consolidate numeric predicted star:\n",
    "    # Prefer parsed JSON numeric field for P1 -> P2 -> P3 (or regex fallback), else None\n",
    "    predicted = None\n",
    "    for s in (star_1, star_2, star_3):\n",
    "        if s is not None:\n",
    "            predicted = s\n",
    "            break\n",
    "\n",
    "    # Build result record\n",
    "    results.append({\n",
    "        \"review\": review_text,\n",
    "        \"actual\": actual,\n",
    "        \"p1_raw\": raw_1,\n",
    "        \"p1_parsed\": parsed_1,\n",
    "        \"p1_star\": star_1,\n",
    "        \"p2_raw\": raw_2,\n",
    "        \"p2_parsed\": parsed_2,\n",
    "        \"p2_star\": star_2,\n",
    "        \"p3_raw\": raw_3,\n",
    "        \"p3_parsed\": parsed_3,\n",
    "        \"p3_star\": star_3,\n",
    "        \"predicted_stars\": predicted\n",
    "    })\n",
    "\n",
    "    # polite delay to avoid thrashing memory / I/O\n",
    "    time.sleep(REQUEST_DELAY)\n",
    "\n",
    "    if (idx + 1) % 10 == 0 or (idx + 1) == n:\n",
    "        print(f\"Processed {idx + 1}/{n} reviews. Latest predicted: {predicted}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4f857115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Saved results_with_predictions.csv and evaluation_summary.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>json_validity</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prompt 1 (Zero-shot)</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prompt 2 (Few-shot)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prompt 3 (CoT)</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Final (first available p1-&gt;p2-&gt;p3)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               prompt  json_validity  accuracy\n",
       "0                Prompt 1 (Zero-shot)            0.8       0.4\n",
       "1                 Prompt 2 (Few-shot)            1.0       0.7\n",
       "2                      Prompt 3 (CoT)            0.5       0.3\n",
       "3  Final (first available p1->p2->p3)            1.0       0.4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>actual</th>\n",
       "      <th>p1_raw</th>\n",
       "      <th>p1_parsed</th>\n",
       "      <th>p1_star</th>\n",
       "      <th>p2_raw</th>\n",
       "      <th>p2_parsed</th>\n",
       "      <th>p2_star</th>\n",
       "      <th>p3_raw</th>\n",
       "      <th>p3_parsed</th>\n",
       "      <th>p3_star</th>\n",
       "      <th>predicted_stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This place has a great selection of Korean dis...</td>\n",
       "      <td>4</td>\n",
       "      <td>model='llama3.2:latest' created_at='2025-12-07...</td>\n",
       "      <td>{'predicted_stars': 4, 'explanation': 'Great s...</td>\n",
       "      <td>4</td>\n",
       "      <td>model='llama3.2:latest' created_at='2025-12-07...</td>\n",
       "      <td>{'predicted_stars': 5, 'explanation': 'very po...</td>\n",
       "      <td>5</td>\n",
       "      <td>model='llama3.2:latest' created_at='2025-12-07...</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This place is the best place I've found so far...</td>\n",
       "      <td>5</td>\n",
       "      <td>model='llama3.2:latest' created_at='2025-12-07...</td>\n",
       "      <td>{'predicted_stars': 4, 'explanation': 'Excelle...</td>\n",
       "      <td>4</td>\n",
       "      <td>model='llama3.2:latest' created_at='2025-12-07...</td>\n",
       "      <td>{'predicted_stars': 5, 'explanation': 'very po...</td>\n",
       "      <td>5</td>\n",
       "      <td>model='llama3.2:latest' created_at='2025-12-07...</td>\n",
       "      <td>{'predicted_stars': 4, 'explanation': 'The rev...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Okay, I will start out by saying that I just p...</td>\n",
       "      <td>5</td>\n",
       "      <td>model='llama3.2:latest' created_at='2025-12-07...</td>\n",
       "      <td>{'predicted_stars': 4, 'explanation': 'Excelle...</td>\n",
       "      <td>4</td>\n",
       "      <td>model='llama3.2:latest' created_at='2025-12-07...</td>\n",
       "      <td>{'predicted_stars': 5, 'explanation': 'very po...</td>\n",
       "      <td>5</td>\n",
       "      <td>model='llama3.2:latest' created_at='2025-12-07...</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My husband and I heard great reviews about thi...</td>\n",
       "      <td>1</td>\n",
       "      <td>model='llama3.2:latest' created_at='2025-12-07...</td>\n",
       "      <td>{'predicted_stars': 1, 'explanation': 'extreme...</td>\n",
       "      <td>1</td>\n",
       "      <td>model='llama3.2:latest' created_at='2025-12-07...</td>\n",
       "      <td>{'predicted_stars': 1, 'explanation': 'very ne...</td>\n",
       "      <td>1</td>\n",
       "      <td>model='llama3.2:latest' created_at='2025-12-07...</td>\n",
       "      <td>{'predicted_stars': 1, 'explanation': 'The rev...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Where I live in Tempe, I can walk to the end o...</td>\n",
       "      <td>3</td>\n",
       "      <td>model='llama3.2:latest' created_at='2025-12-07...</td>\n",
       "      <td>{'predicted_stars': 4, 'explanation': 'General...</td>\n",
       "      <td>4</td>\n",
       "      <td>model='llama3.2:latest' created_at='2025-12-07...</td>\n",
       "      <td>{'predicted_stars': 4, 'explanation': 'mostly ...</td>\n",
       "      <td>4</td>\n",
       "      <td>model='llama3.2:latest' created_at='2025-12-07...</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  actual  \\\n",
       "0  This place has a great selection of Korean dis...       4   \n",
       "1  This place is the best place I've found so far...       5   \n",
       "2  Okay, I will start out by saying that I just p...       5   \n",
       "3  My husband and I heard great reviews about thi...       1   \n",
       "4  Where I live in Tempe, I can walk to the end o...       3   \n",
       "\n",
       "                                              p1_raw  \\\n",
       "0  model='llama3.2:latest' created_at='2025-12-07...   \n",
       "1  model='llama3.2:latest' created_at='2025-12-07...   \n",
       "2  model='llama3.2:latest' created_at='2025-12-07...   \n",
       "3  model='llama3.2:latest' created_at='2025-12-07...   \n",
       "4  model='llama3.2:latest' created_at='2025-12-07...   \n",
       "\n",
       "                                           p1_parsed  p1_star  \\\n",
       "0  {'predicted_stars': 4, 'explanation': 'Great s...        4   \n",
       "1  {'predicted_stars': 4, 'explanation': 'Excelle...        4   \n",
       "2  {'predicted_stars': 4, 'explanation': 'Excelle...        4   \n",
       "3  {'predicted_stars': 1, 'explanation': 'extreme...        1   \n",
       "4  {'predicted_stars': 4, 'explanation': 'General...        4   \n",
       "\n",
       "                                              p2_raw  \\\n",
       "0  model='llama3.2:latest' created_at='2025-12-07...   \n",
       "1  model='llama3.2:latest' created_at='2025-12-07...   \n",
       "2  model='llama3.2:latest' created_at='2025-12-07...   \n",
       "3  model='llama3.2:latest' created_at='2025-12-07...   \n",
       "4  model='llama3.2:latest' created_at='2025-12-07...   \n",
       "\n",
       "                                           p2_parsed  p2_star  \\\n",
       "0  {'predicted_stars': 5, 'explanation': 'very po...        5   \n",
       "1  {'predicted_stars': 5, 'explanation': 'very po...        5   \n",
       "2  {'predicted_stars': 5, 'explanation': 'very po...        5   \n",
       "3  {'predicted_stars': 1, 'explanation': 'very ne...        1   \n",
       "4  {'predicted_stars': 4, 'explanation': 'mostly ...        4   \n",
       "\n",
       "                                              p3_raw  \\\n",
       "0  model='llama3.2:latest' created_at='2025-12-07...   \n",
       "1  model='llama3.2:latest' created_at='2025-12-07...   \n",
       "2  model='llama3.2:latest' created_at='2025-12-07...   \n",
       "3  model='llama3.2:latest' created_at='2025-12-07...   \n",
       "4  model='llama3.2:latest' created_at='2025-12-07...   \n",
       "\n",
       "                                           p3_parsed  p3_star  predicted_stars  \n",
       "0                                               None        2                4  \n",
       "1  {'predicted_stars': 4, 'explanation': 'The rev...        4                4  \n",
       "2                                               None        2                4  \n",
       "3  {'predicted_stars': 1, 'explanation': 'The rev...        1                1  \n",
       "4                                               None        2                4  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save to dataframe + csv\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"results_with_predictions.csv\", index=False)\n",
    "\n",
    "# Compute per-prompt metrics\n",
    "p1_json_rate = p1_json_count / n\n",
    "p2_json_rate = p2_json_count / n\n",
    "p3_json_rate = p3_json_count / n\n",
    "\n",
    "p1_accuracy = p1_correct / n\n",
    "p2_accuracy = p2_correct / n\n",
    "p3_accuracy = p3_correct / n\n",
    "\n",
    "# Overall predicted accuracy (based on consolidated 'predicted_stars' column)\n",
    "valid_final_mask = results_df[\"predicted_stars\"].notnull()\n",
    "if valid_final_mask.sum() > 0:\n",
    "    final_accuracy = (results_df.loc[valid_final_mask, \"predicted_stars\"].astype(int) == results_df.loc[valid_final_mask, \"actual\"].astype(int)).mean()\n",
    "else:\n",
    "    final_accuracy = 0.0\n",
    "\n",
    "summary = pd.DataFrame([\n",
    "    {\"prompt\": \"Prompt 1 (Zero-shot)\", \"json_validity\": p1_json_rate, \"accuracy\": p1_accuracy},\n",
    "    {\"prompt\": \"Prompt 2 (Few-shot)\",  \"json_validity\": p2_json_rate, \"accuracy\": p2_accuracy},\n",
    "    {\"prompt\": \"Prompt 3 (CoT)\",       \"json_validity\": p3_json_rate, \"accuracy\": p3_accuracy},\n",
    "    {\"prompt\": \"Final (first available p1->p2->p3)\", \"json_validity\": valid_final_mask.mean(), \"accuracy\": final_accuracy}\n",
    "])\n",
    "\n",
    "summary.to_csv(\"evaluation_summary.csv\", index=False)\n",
    "\n",
    "print(\"Done. Saved results_with_predictions.csv and evaluation_summary.csv\")\n",
    "display(summary)\n",
    "results_df.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ai_agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
